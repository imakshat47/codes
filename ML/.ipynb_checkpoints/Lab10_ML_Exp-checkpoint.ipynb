{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A feed-forward neural network"
      ],
      "metadata": {
        "id": "PxmNGNug-Czl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M74hvjW8wXd",
        "outputId": "1a59850d-c659-44ec-9532-2c62c66b2b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5183 - loss: 1.1869 - val_accuracy: 0.5060 - val_loss: 0.7724\n",
            "Epoch 2/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5644 - loss: 0.6981 - val_accuracy: 0.5640 - val_loss: 0.6808\n",
            "Epoch 3/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5776 - loss: 0.6757 - val_accuracy: 0.5250 - val_loss: 0.7649\n",
            "Epoch 4/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5696 - loss: 0.6821 - val_accuracy: 0.5260 - val_loss: 0.7122\n",
            "Epoch 5/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5763 - loss: 0.6815 - val_accuracy: 0.5790 - val_loss: 0.6734\n",
            "Epoch 6/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6130 - loss: 0.6520 - val_accuracy: 0.5730 - val_loss: 0.6818\n",
            "Epoch 7/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.6052 - loss: 0.6587 - val_accuracy: 0.5860 - val_loss: 0.6668\n",
            "Epoch 8/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6148 - loss: 0.6457 - val_accuracy: 0.5650 - val_loss: 0.6727\n",
            "Epoch 9/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6083 - loss: 0.6504 - val_accuracy: 0.5800 - val_loss: 0.6833\n",
            "Epoch 10/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6165 - loss: 0.6466 - val_accuracy: 0.5780 - val_loss: 0.6895\n",
            "Epoch 11/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6187 - loss: 0.6494 - val_accuracy: 0.5870 - val_loss: 0.6645\n",
            "Epoch 12/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6092 - loss: 0.6484 - val_accuracy: 0.5920 - val_loss: 0.6651\n",
            "Epoch 13/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6233 - loss: 0.6397 - val_accuracy: 0.6070 - val_loss: 0.6541\n",
            "Epoch 14/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6257 - loss: 0.6347 - val_accuracy: 0.5670 - val_loss: 0.6825\n",
            "Epoch 15/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.6360 - loss: 0.6326 - val_accuracy: 0.5400 - val_loss: 0.6915\n",
            "Epoch 16/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6262 - loss: 0.6373 - val_accuracy: 0.5950 - val_loss: 0.6605\n",
            "Epoch 17/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6406 - loss: 0.6320 - val_accuracy: 0.6030 - val_loss: 0.6632\n",
            "Epoch 18/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6337 - loss: 0.6297 - val_accuracy: 0.5530 - val_loss: 0.7048\n",
            "Epoch 19/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.6292 - loss: 0.6320 - val_accuracy: 0.5980 - val_loss: 0.6697\n",
            "Epoch 20/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6385 - loss: 0.6261 - val_accuracy: 0.6020 - val_loss: 0.6557\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.6628\n",
            "Test accuracy: 0.6245\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load CIFAR-10 and filter for cats (3) and dogs (5)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "\n",
        "mask_train = np.isin(y_train, [3, 5])\n",
        "mask_test  = np.isin(y_test, [3, 5])\n",
        "x_train, y_train = x_train[mask_train], y_train[mask_train]\n",
        "x_test, y_test   = x_test[mask_test],   y_test[mask_test]\n",
        "\n",
        "# Map labels: cat → 0, dog → 1\n",
        "y_train = (y_train == 5).astype('int32')\n",
        "y_test  = (y_test  == 5).astype('int32')\n",
        "\n",
        "# 2. Preprocess: Normalize and flatten images\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test  = x_test.astype('float32')  / 255.0\n",
        "x_train = x_train.reshape(-1, 32*32*3)\n",
        "x_test  = x_test.reshape(-1, 32*32*3)\n",
        "\n",
        "# 3. Build feed-forward model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(32*32*3,)),         # Flattened input\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(2)                         # Two outputs: cat vs. dog\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)\n",
        "\n",
        "# 5. Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A back propagation neural network"
      ],
      "metadata": {
        "id": "EZVMhsfW-Gmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "# 1. Load CIFAR-10 and filter cats vs. dogs\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()  # :contentReference[oaicite:5]{index=5}\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "mask_train = np.isin(y_train, [3,5]); mask_test = np.isin(y_test, [3,5])\n",
        "x_train, y_train = x_train[mask_train], y_train[mask_train]\n",
        "x_test, y_test   = x_test[mask_test],   y_test[mask_test]\n",
        "y_train = (y_train == 5).astype('int32'); y_test = (y_test == 5).astype('int32')\n",
        "# 2. Preprocess: Normalize & flatten\n",
        "x_train = x_train.astype('float32')/255.0; x_test = x_test.astype('float32')/255.0  # :contentReference[oaicite:6]{index=6}\n",
        "x_train = x_train.reshape(-1, 32*32*3); x_test = x_test.reshape(-1, 32*32*3)\n",
        "# 3. Build the model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(32*32*3,)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(2)       # logits\n",
        "])  # :contentReference[oaicite:7]{index=7}\n",
        "# 4. Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "# 5. Train\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)\n",
        "# 6. Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l73dZiQf9T1D",
        "outputId": "03a89578-7dff-42c0-93ec-f46978b076ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5168 - loss: 1.0989 - val_accuracy: 0.5790 - val_loss: 0.6741\n",
            "Epoch 2/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5864 - loss: 0.6698 - val_accuracy: 0.5300 - val_loss: 0.7292\n",
            "Epoch 3/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.5636 - loss: 0.6921 - val_accuracy: 0.5810 - val_loss: 0.6689\n",
            "Epoch 4/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5814 - loss: 0.6817 - val_accuracy: 0.5630 - val_loss: 0.6763\n",
            "Epoch 5/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6035 - loss: 0.6580 - val_accuracy: 0.5850 - val_loss: 0.6653\n",
            "Epoch 6/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5922 - loss: 0.6591 - val_accuracy: 0.6040 - val_loss: 0.6598\n",
            "Epoch 7/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6132 - loss: 0.6471 - val_accuracy: 0.5940 - val_loss: 0.6608\n",
            "Epoch 8/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6008 - loss: 0.6570 - val_accuracy: 0.5720 - val_loss: 0.6817\n",
            "Epoch 9/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6215 - loss: 0.6436 - val_accuracy: 0.6070 - val_loss: 0.6585\n",
            "Epoch 10/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6282 - loss: 0.6402 - val_accuracy: 0.5860 - val_loss: 0.6651\n",
            "Epoch 11/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6267 - loss: 0.6398 - val_accuracy: 0.5950 - val_loss: 0.6613\n",
            "Epoch 12/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6269 - loss: 0.6362 - val_accuracy: 0.6150 - val_loss: 0.6563\n",
            "Epoch 13/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6368 - loss: 0.6332 - val_accuracy: 0.6000 - val_loss: 0.6618\n",
            "Epoch 14/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6298 - loss: 0.6347 - val_accuracy: 0.6020 - val_loss: 0.6754\n",
            "Epoch 15/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6297 - loss: 0.6326 - val_accuracy: 0.6160 - val_loss: 0.6549\n",
            "Epoch 16/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6391 - loss: 0.6287 - val_accuracy: 0.5960 - val_loss: 0.6539\n",
            "Epoch 17/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.6373 - loss: 0.6233 - val_accuracy: 0.6080 - val_loss: 0.6600\n",
            "Epoch 18/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6533 - loss: 0.6153 - val_accuracy: 0.6150 - val_loss: 0.6502\n",
            "Epoch 19/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6527 - loss: 0.6147 - val_accuracy: 0.5900 - val_loss: 0.6692\n",
            "Epoch 20/20\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6552 - loss: 0.6122 - val_accuracy: 0.5790 - val_loss: 0.6812\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5923 - loss: 0.6872\n",
            "Test accuracy: 0.5950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load & Filter CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "mask_train = np.isin(y_train, [3,5]); mask_test = np.isin(y_test, [3,5])\n",
        "x_train, y_train = x_train[mask_train], (y_train[mask_train]==5).astype('int32')\n",
        "x_test,  y_test  = x_test[mask_test],  (y_test[mask_test]==5).astype('int32')\n",
        "\n",
        "# 2. Data Augmentation\n",
        "data_augment = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# 3. Preprocess: normalize & flatten\n",
        "def preprocess(x, y):\n",
        "    x = tf.cast(x, tf.float32)/255.0\n",
        "    x = tf.reshape(x, (-1, 32*32*3))\n",
        "    return x, y\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(5000).batch(128)\n",
        "train_ds = train_ds.map(lambda x,y: (data_augment(x), y)).map(preprocess).prefetch(1)\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128).map(preprocess)\n",
        "\n",
        "# 4. Model with Dropout & BatchNorm\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(32*32*3,)),\n",
        "    layers.Dense(1024, activation=None),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(512, activation=None),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(256, activation=None),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(2)  # logits\n",
        "])\n",
        "\n",
        "# 5. Compile with LR Scheduler\n",
        "# Remove the learning rate schedule from the optimizer definition\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),  # Remove learning_rate=lr_schedule\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 6. Callbacks\n",
        "def lr_schedule(epoch):\n",
        "  \"\"\"Learning Rate Schedule\n",
        "\n",
        "  Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "  Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "  # Arguments\n",
        "      epoch (int): The number of epochs\n",
        "\n",
        "  # Returns\n",
        "      lr (float32): learning rate\n",
        "  \"\"\"\n",
        "  lr = 1e-3\n",
        "  if epoch > 180:\n",
        "    lr *= 0.5e-3\n",
        "  elif epoch > 160:\n",
        "    lr *= 1e-3\n",
        "  elif epoch > 120:\n",
        "    lr *= 1e-2\n",
        "  elif epoch > 80:\n",
        "    lr *= 1e-1\n",
        "  print('Learning rate: ', lr)\n",
        "  return lr\n",
        "# Add LearningRateScheduler callback to manage the learning rate\n",
        "cb = [\n",
        "    callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
        "    callbacks.LearningRateScheduler(lr_schedule)  # Add this line\n",
        "]\n",
        "\n",
        "# 7. Train & Evaluate\n",
        "history = model.fit(train_ds, epochs=30, validation_data=test_ds, callbacks=cb)\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CNC31Sb97gY",
        "outputId": "1ff4cbe8-8f5d-4827-c813-2bb3bce2cbec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Epoch 1/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - accuracy: 0.5368 - loss: 0.8424 - val_accuracy: 0.5615 - val_loss: 0.8004 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.5763 - loss: 0.7050 - val_accuracy: 0.5620 - val_loss: 0.7371 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - accuracy: 0.5631 - loss: 0.7068 - val_accuracy: 0.5945 - val_loss: 0.6747 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.5750 - loss: 0.6854 - val_accuracy: 0.6130 - val_loss: 0.6788 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - accuracy: 0.5952 - loss: 0.6689 - val_accuracy: 0.6100 - val_loss: 0.6515 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.6046 - loss: 0.6662 - val_accuracy: 0.6225 - val_loss: 0.6459 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.6049 - loss: 0.6585 - val_accuracy: 0.6255 - val_loss: 0.6483 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.6090 - loss: 0.6562 - val_accuracy: 0.6375 - val_loss: 0.6378 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.5987 - loss: 0.6570 - val_accuracy: 0.5890 - val_loss: 0.6680 - learning_rate: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - accuracy: 0.6248 - loss: 0.6434 - val_accuracy: 0.6110 - val_loss: 0.6480 - learning_rate: 5.0000e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 11/30\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.6285 - loss: 0.6409 - val_accuracy: 0.5820 - val_loss: 0.6844 - learning_rate: 0.0010\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6351 - loss: 0.6420\n",
            "Test accuracy: 0.6375\n"
          ]
        }
      ]
    }
  ]
}