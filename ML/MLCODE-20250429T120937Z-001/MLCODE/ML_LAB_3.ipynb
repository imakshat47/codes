{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W98C5TXxPLpr"
   },
   "source": [
    "# **Web Scraping**\n",
    "\n",
    "**Problem Statement:** Your task is to extract data from an online bookstore to analyse the available books based on their categories, ratings, prices, and availability. You aim to scrape the required data from the website and perform basic data analysis.\n",
    "\n",
    "**Website for Scraping:** Use the publicly available website https://books.toscrape.com/. The site contains various books across multiple categories with details like title, price, rating, and stock status.\n",
    "\n",
    "Tasks in order:\n",
    "1. **Scrape Book Information:** Navigate to the website and extract data for all books available. For each book, extract the following details:\n",
    " * Title\n",
    " * Price\n",
    " * Rating (e.g., 1-star, 2-star, etc.)\n",
    " * Availability (In stock or Out of stock)\n",
    "2. **Organize the Data:** Store the extracted data in a structured format such as a CSV file or a Pandas DataFrame.\n",
    "3. **Categorize the Data:** Identify the category of each book and include it in your data.\n",
    "4. **Basic Analysis:**\n",
    "  * Calculate the average price of books in each category.\n",
    "  * Find the most frequent rating for books.\n",
    "  * Identify the category with the highest number of books available.\n",
    "5. Create a visualization plot showing the number of books per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1737474301147,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "vNmRygA4Ozbp"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737474303012,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "7zNPCIDoRVNq"
   },
   "outputs": [],
   "source": [
    "# Define helper function\n",
    "BASE_URL = \"https://books.toscrape.com/\"\n",
    "\n",
    "def get_soup(url):\n",
    "    \"\"\"Fetch a webpage and return a BeautifulSoup object.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.content, \"html.parser\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch page: {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_book_data(soup):\n",
    "    \"\"\"Extract book data from a single page.\"\"\"\n",
    "    books = []\n",
    "    for book in soup.find_all('article', class_='product_pod'):\n",
    "        # Book details\n",
    "        title = book.h3.a['title']\n",
    "        price = float(book.find('p', class_='price_color').text[1:])\n",
    "        rating = book.p['class'][1]  # e.g., \"One\", \"Two\"\n",
    "        availability = book.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "        # Navigate to the book's page to fetch the category\n",
    "        book_url = BASE_URL + \"catalogue/\" + book.h3.a['href']\n",
    "        book_soup = get_soup(book_url)\n",
    "        category = get_category(book_soup) if book_soup else \"Unknown\"\n",
    "\n",
    "        books.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Rating': rating,\n",
    "            'Availability': availability,\n",
    "            'Category': category\n",
    "        })\n",
    "    return books\n",
    "\n",
    "def get_category(soup):\n",
    "    \"\"\"Extract category of books from the current page.\"\"\"\n",
    "    breadcrumb = soup.find('ul', class_='breadcrumb')\n",
    "    if breadcrumb:\n",
    "        breadcrumb_items = breadcrumb.find_all('li')\n",
    "        if len(breadcrumb_items) > 2:\n",
    "            return breadcrumb_items[2].text.strip()\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def scrape_books():\n",
    "    \"\"\"Scrape all book data from the website.\"\"\"\n",
    "    all_books = []\n",
    "    page_url = BASE_URL + 'catalogue/page-1.html'  # Starting page\n",
    "\n",
    "    while page_url:\n",
    "        soup = get_soup(page_url)\n",
    "        if not soup:\n",
    "            break\n",
    "\n",
    "        books = extract_book_data(soup)  # Now fetches category from the book's page\n",
    "        all_books.extend(books)\n",
    "\n",
    "        # Check for next page\n",
    "        next_page = soup.find('li', class_='next')\n",
    "        if next_page:\n",
    "            next_page_url = next_page.a['href']\n",
    "            page_url = BASE_URL + 'catalogue/' + next_page_url\n",
    "        else:\n",
    "            page_url = None\n",
    "\n",
    "    return pd.DataFrame(all_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304152,
     "status": "ok",
     "timestamp": 1737474609810,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "bMpHVtFyR1_w",
    "outputId": "a7173fa0-ccba-460b-e481-9740c31c5e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping book data...\n"
     ]
    }
   ],
   "source": [
    "# Scrape Data\n",
    "print(\"Scraping book data...\")\n",
    "books_df = scrape_books()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1737474619636,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "Vyy5C6ZfR6lc",
    "outputId": "7e7a6ba6-9caa-4735-b9b5-0ea279a55031"
   },
   "outputs": [],
   "source": [
    "# Save Data to CSV\n",
    "print(\"Saving data to CSV...\")\n",
    "books_df.to_csv('books_data.csv', index=False)\n",
    "books_df.head()  # Display the first few rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1737474625163,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "i4G5s-piSuI2",
    "outputId": "c27c0351-d761-4560-8a17-67d3b74501ab"
   },
   "outputs": [],
   "source": [
    "# Perform Data Analysis\n",
    "print(\"Analyzing data...\")\n",
    "\n",
    "# Average price per category\n",
    "average_price = books_df.groupby('Category')['Price'].mean()\n",
    "print(\"\\nAverage price per category:\")\n",
    "print(average_price)\n",
    "\n",
    "# Most frequent rating\n",
    "most_frequent_rating = books_df['Rating'].mode()[0]\n",
    "print(\"\\nMost frequent rating:\")\n",
    "print(most_frequent_rating)\n",
    "\n",
    "# Category with the most books\n",
    "most_books_category = books_df['Category'].value_counts().idxmax()\n",
    "print(\"\\nCategory with the most books:\")\n",
    "print(most_books_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 2065,
     "status": "ok",
     "timestamp": 1737474649157,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "kLVbzXbES0qR",
    "outputId": "a883c42e-9bb7-44e8-a04f-3a3da08292c8"
   },
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "print(\"Visualizing data...\")\n",
    "\n",
    "# Bar plot for the number of books per category\n",
    "category_counts = books_df['Category'].value_counts()\n",
    "category_counts.plot(kind='bar', figsize=(24,6))\n",
    "plt.title('Number of Books per Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1737474639168,
     "user": {
      "displayName": "Arwaz Khan",
      "userId": "06817873676322380190"
     },
     "user_tz": -330
    },
    "id": "FQSpw82oTD5N",
    "outputId": "8cf18463-20c7-478b-decf-d35a5671e01e"
   },
   "outputs": [],
   "source": [
    "# Download the CSV File\n",
    "#files.download('books_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0ZvpYyRo7e+mk0ftPi/gk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
