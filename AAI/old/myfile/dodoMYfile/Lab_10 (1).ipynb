{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##**Name - Affan**\n","##**Roll No. - 242210001**\n","##**Date - 15/04/2025**"],"metadata":{"id":"BuOxdDJr8CvN"}},{"cell_type":"markdown","source":["# **1. Image classification using a feed-forward neural network**"],"metadata":{"id":"ass5Z_487S3u"}},{"cell_type":"code","source":["import kagglehub\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","dataset_path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n","\n","cat_dir = os.path.join(dataset_path, \"PetImages\", \"Cat\")\n","dog_dir = os.path.join(dataset_path, \"PetImages\", \"Dog\")\n","\n","IMG_SIZE = 128\n","LIMIT = 1000\n","data, labels = [], []\n","\n","def load_images_from_folder(folder, label, limit=1000):\n","    count = 0\n","    for filename in os.listdir(folder):\n","        if count >= limit:\n","            break\n","        img_path = os.path.join(folder, filename)\n","        try:\n","            img = cv2.imread(img_path)\n","            if img is not None:\n","                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","                data.append(img)\n","                labels.append(label)\n","                count += 1\n","        except:\n","            continue\n","\n","load_images_from_folder(dog_dir, label=1, limit=LIMIT)\n","load_images_from_folder(cat_dir, label=0, limit=LIMIT)\n","\n","X = np.array(data, dtype='float32') / 255.0\n","y = np.array(labels)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Building FFNN model\n","model = Sequential([\n","    Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n","    Dense(256, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n","\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"\\n Final Test Accuracy: {accuracy:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MNCoZbh17D3","outputId":"a871bacd-2742-439f-afd6-9f4a2e688974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/dog-and-cat-classification-dataset?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 775M/775M [00:35<00:00, 23.2MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5087 - loss: 7.2072 - val_accuracy: 0.5025 - val_loss: 2.2108\n","Epoch 2/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5613 - loss: 1.2544 - val_accuracy: 0.5250 - val_loss: 0.9729\n","Epoch 3/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6199 - loss: 0.7514 - val_accuracy: 0.6050 - val_loss: 0.8503\n","Epoch 4/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6225 - loss: 0.7644 - val_accuracy: 0.6050 - val_loss: 0.6718\n","Epoch 5/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6695 - loss: 0.6252 - val_accuracy: 0.6450 - val_loss: 0.6509\n","Epoch 6/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6243 - loss: 0.7664 - val_accuracy: 0.5025 - val_loss: 1.8046\n","Epoch 7/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5863 - loss: 1.0005 - val_accuracy: 0.5350 - val_loss: 0.7238\n","Epoch 8/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6063 - loss: 0.6847 - val_accuracy: 0.5750 - val_loss: 0.6979\n","Epoch 9/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.5962 - val_accuracy: 0.6575 - val_loss: 0.6437\n","Epoch 10/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6370 - loss: 0.6692 - val_accuracy: 0.6000 - val_loss: 0.7262\n","Epoch 11/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6975 - loss: 0.5816 - val_accuracy: 0.5700 - val_loss: 0.8280\n","Epoch 12/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7071 - loss: 0.5648 - val_accuracy: 0.6025 - val_loss: 0.6917\n","Epoch 13/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7125 - loss: 0.5547 - val_accuracy: 0.5850 - val_loss: 0.8002\n","Epoch 14/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7096 - loss: 0.5482 - val_accuracy: 0.6375 - val_loss: 0.6666\n","Epoch 15/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6436 - loss: 0.6408 - val_accuracy: 0.5575 - val_loss: 0.7681\n","Epoch 16/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6910 - loss: 0.5649 - val_accuracy: 0.6275 - val_loss: 0.6868\n","Epoch 17/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7234 - loss: 0.5208 - val_accuracy: 0.6425 - val_loss: 0.6616\n","Epoch 18/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.5505 - val_accuracy: 0.6300 - val_loss: 0.6893\n","Epoch 19/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7470 - loss: 0.5071 - val_accuracy: 0.6275 - val_loss: 0.6896\n","Epoch 20/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7609 - loss: 0.4796 - val_accuracy: 0.5650 - val_loss: 0.9266\n","Epoch 21/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6680 - loss: 0.5941 - val_accuracy: 0.6625 - val_loss: 0.7200\n","Epoch 22/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7203 - loss: 0.5590 - val_accuracy: 0.6225 - val_loss: 0.7107\n","Epoch 23/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7215 - loss: 0.5515 - val_accuracy: 0.5700 - val_loss: 0.8040\n","Epoch 24/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7217 - loss: 0.5531 - val_accuracy: 0.5900 - val_loss: 0.8042\n","Epoch 25/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7304 - loss: 0.5227 - val_accuracy: 0.6425 - val_loss: 0.7672\n","Epoch 26/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7503 - loss: 0.4907 - val_accuracy: 0.5700 - val_loss: 0.8111\n","Epoch 27/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7734 - loss: 0.4933 - val_accuracy: 0.5925 - val_loss: 0.7919\n","Epoch 28/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7774 - loss: 0.4628 - val_accuracy: 0.6700 - val_loss: 0.7232\n","Epoch 29/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8083 - loss: 0.4206 - val_accuracy: 0.6000 - val_loss: 0.7728\n","Epoch 30/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8028 - loss: 0.4232 - val_accuracy: 0.5475 - val_loss: 1.1757\n","Epoch 31/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7871 - loss: 0.4484 - val_accuracy: 0.6200 - val_loss: 0.7659\n","Epoch 32/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7943 - loss: 0.4314 - val_accuracy: 0.6150 - val_loss: 0.8510\n","Epoch 33/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8053 - loss: 0.4164 - val_accuracy: 0.6350 - val_loss: 0.8177\n","Epoch 34/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8095 - loss: 0.4174 - val_accuracy: 0.5700 - val_loss: 0.7892\n","Epoch 35/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7481 - loss: 0.5099 - val_accuracy: 0.6125 - val_loss: 0.7633\n","Epoch 36/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8422 - loss: 0.3871 - val_accuracy: 0.5500 - val_loss: 0.9427\n","Epoch 37/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7978 - loss: 0.4301 - val_accuracy: 0.6075 - val_loss: 0.8523\n","Epoch 38/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7557 - loss: 0.4646 - val_accuracy: 0.6350 - val_loss: 0.7922\n","Epoch 39/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7826 - loss: 0.4282 - val_accuracy: 0.6250 - val_loss: 0.8369\n","Epoch 40/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8555 - loss: 0.3272 - val_accuracy: 0.6350 - val_loss: 0.8026\n","Epoch 41/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8830 - loss: 0.2958 - val_accuracy: 0.5875 - val_loss: 1.1248\n","Epoch 42/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8056 - loss: 0.4329 - val_accuracy: 0.6300 - val_loss: 0.7776\n","Epoch 43/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8647 - loss: 0.3332 - val_accuracy: 0.6175 - val_loss: 0.9789\n","Epoch 44/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8871 - loss: 0.2661 - val_accuracy: 0.6050 - val_loss: 1.0084\n","Epoch 45/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8672 - loss: 0.3102 - val_accuracy: 0.5850 - val_loss: 1.1567\n","Epoch 46/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8224 - loss: 0.4137 - val_accuracy: 0.5825 - val_loss: 0.8188\n","Epoch 47/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.4078 - val_accuracy: 0.6150 - val_loss: 0.9199\n","Epoch 48/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8533 - loss: 0.3333 - val_accuracy: 0.6225 - val_loss: 1.0529\n","Epoch 49/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8415 - loss: 0.3568 - val_accuracy: 0.5850 - val_loss: 0.9654\n","Epoch 50/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8185 - loss: 0.3705 - val_accuracy: 0.5875 - val_loss: 1.0390\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 1.0558\n","\n"," Final Test Accuracy: 0.5875\n"]}]},{"cell_type":"markdown","source":["##**Q. What were the limitations of FFNNs with high-dimensional image inputs?**\n","\n","**Ans.** Feed-Forward Neural Networks (FFNNs) have several limitations when used with high-dimensional image inputs. They require flattening the image, which causes the loss of crucial spatial relationships between pixels. As image size increases, FFNNs also suffer from the curse of dimensionality, leading to a massive number of parameters, increased memory usage, and a higher risk of overfitting. And Unlike Convolutional Neural Networks (CNNs), FFNNs often need manual feature extraction, making them less practical for complex visual data."],"metadata":{"id":"ug410qgY5X5F"}},{"cell_type":"markdown","source":["# **2. Image classification using back propagation neural network**"],"metadata":{"id":"Ed114ZKC7miG"}},{"cell_type":"code","source":["import kagglehub\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","IMG_SIZE = 128\n","LIMIT = 1000\n","\n","data, labels = [], []\n","\n","def load_images(folder, label, limit=1000):\n","    count = 0\n","    for file in os.listdir(folder):\n","        if count >= limit:\n","            break\n","        try:\n","            img_path = os.path.join(folder, file)\n","            img = cv2.imread(img_path)\n","            if img is not None:\n","                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","                data.append(img)\n","                labels.append(label)\n","                count += 1\n","        except:\n","            continue\n","\n","load_images(cat_dir, label=0, limit=LIMIT)\n","load_images(dog_dir, label=1, limit=LIMIT)\n","\n","X = np.array(data, dtype='float32') / 255.0\n","y = np.array(labels)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Building Backpropagation Neural Network\n","model = Sequential([\n","    Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n","    Dense(256, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","\n","model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n","\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f\"\\n Test Accuracy: {acc:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CBqPeOf6XYl","outputId":"fbba85a2-bc78-40f7-f3ae-6d4d2a02fafb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5090 - loss: 5.2726 - val_accuracy: 0.5275 - val_loss: 0.7155\n","Epoch 2/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5452 - loss: 0.8748 - val_accuracy: 0.5075 - val_loss: 0.8571\n","Epoch 3/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5860 - loss: 0.8712 - val_accuracy: 0.5325 - val_loss: 0.7284\n","Epoch 4/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6074 - loss: 0.7113 - val_accuracy: 0.5175 - val_loss: 0.7335\n","Epoch 5/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6412 - loss: 0.6354 - val_accuracy: 0.5200 - val_loss: 0.8979\n","Epoch 6/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6399 - loss: 0.6383 - val_accuracy: 0.5600 - val_loss: 0.7330\n","Epoch 7/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6505 - loss: 0.6168 - val_accuracy: 0.5325 - val_loss: 0.8077\n","Epoch 8/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6472 - loss: 0.6305 - val_accuracy: 0.5225 - val_loss: 0.9422\n","Epoch 9/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6404 - loss: 0.6556 - val_accuracy: 0.5075 - val_loss: 0.9000\n","Epoch 10/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6072 - loss: 0.6679 - val_accuracy: 0.5150 - val_loss: 0.9225\n","Epoch 11/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6488 - loss: 0.6461 - val_accuracy: 0.5050 - val_loss: 1.1493\n","Epoch 12/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6304 - loss: 0.6694 - val_accuracy: 0.5325 - val_loss: 0.8221\n","Epoch 13/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6852 - loss: 0.5995 - val_accuracy: 0.5425 - val_loss: 0.7608\n","Epoch 14/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7161 - loss: 0.5642 - val_accuracy: 0.5150 - val_loss: 0.7878\n","Epoch 15/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6367 - loss: 0.6426 - val_accuracy: 0.5275 - val_loss: 0.7724\n","Epoch 16/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6622 - loss: 0.6387 - val_accuracy: 0.5200 - val_loss: 0.7366\n","Epoch 17/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7046 - loss: 0.5624 - val_accuracy: 0.5175 - val_loss: 0.8525\n","Epoch 18/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6983 - loss: 0.5751 - val_accuracy: 0.5300 - val_loss: 0.8729\n","Epoch 19/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7225 - loss: 0.5569 - val_accuracy: 0.5100 - val_loss: 1.0261\n","Epoch 20/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6006 - loss: 0.7198 - val_accuracy: 0.5100 - val_loss: 1.5699\n","Epoch 21/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6277 - loss: 0.7429 - val_accuracy: 0.5675 - val_loss: 0.7793\n","Epoch 22/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6374 - loss: 0.6303 - val_accuracy: 0.5350 - val_loss: 0.8536\n","Epoch 23/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6903 - loss: 0.5907 - val_accuracy: 0.5075 - val_loss: 0.7658\n","Epoch 24/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5621 - loss: 0.6370 - val_accuracy: 0.5300 - val_loss: 0.7242\n","Epoch 25/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6662 - loss: 0.5861 - val_accuracy: 0.5400 - val_loss: 0.7660\n","Epoch 26/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7143 - loss: 0.5587 - val_accuracy: 0.5200 - val_loss: 0.8685\n","Epoch 27/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5867 - loss: 0.6764 - val_accuracy: 0.5025 - val_loss: 0.6922\n","Epoch 28/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5460 - loss: 0.6823 - val_accuracy: 0.5050 - val_loss: 0.7023\n","Epoch 29/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5586 - loss: 0.6654 - val_accuracy: 0.5200 - val_loss: 0.7620\n","Epoch 30/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6164 - loss: 0.6324 - val_accuracy: 0.5125 - val_loss: 0.7005\n","Epoch 31/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6032 - loss: 0.6431 - val_accuracy: 0.5075 - val_loss: 0.7045\n","Epoch 32/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5927 - loss: 0.6425 - val_accuracy: 0.5175 - val_loss: 0.8756\n","Epoch 33/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6020 - loss: 0.6807 - val_accuracy: 0.5150 - val_loss: 0.7658\n","Epoch 34/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5781 - loss: 0.6484 - val_accuracy: 0.5000 - val_loss: 0.6999\n","Epoch 35/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5608 - loss: 0.6616 - val_accuracy: 0.5050 - val_loss: 0.8912\n","Epoch 36/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6125 - loss: 0.6291 - val_accuracy: 0.5100 - val_loss: 0.7582\n","Epoch 37/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6192 - loss: 0.6253 - val_accuracy: 0.5150 - val_loss: 0.7318\n","Epoch 38/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6320 - loss: 0.6200 - val_accuracy: 0.5050 - val_loss: 0.7085\n","Epoch 39/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5872 - loss: 0.6458 - val_accuracy: 0.5275 - val_loss: 0.8336\n","Epoch 40/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6162 - loss: 0.6337 - val_accuracy: 0.5050 - val_loss: 0.7251\n","Epoch 41/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6397 - loss: 0.6016 - val_accuracy: 0.5050 - val_loss: 0.7208\n","Epoch 42/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5576 - loss: 0.6547 - val_accuracy: 0.5200 - val_loss: 0.8728\n","Epoch 43/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6322 - loss: 0.6038 - val_accuracy: 0.5325 - val_loss: 0.8808\n","Epoch 44/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6618 - loss: 0.5809 - val_accuracy: 0.5200 - val_loss: 0.8440\n","Epoch 45/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6554 - loss: 0.5785 - val_accuracy: 0.5025 - val_loss: 0.7381\n","Epoch 46/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6084 - loss: 0.6265 - val_accuracy: 0.5025 - val_loss: 0.7066\n","Epoch 47/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5238 - loss: 0.6842 - val_accuracy: 0.5000 - val_loss: 0.7424\n","Epoch 48/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5908 - loss: 0.6382 - val_accuracy: 0.5175 - val_loss: 0.8440\n","Epoch 49/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6619 - loss: 0.5902 - val_accuracy: 0.5100 - val_loss: 0.7208\n","Epoch 50/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6328 - loss: 0.6180 - val_accuracy: 0.5250 - val_loss: 0.8409\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5182 - loss: 0.8607\n","\n"," Test Accuracy: 0.5250\n"]}]},{"cell_type":"markdown","source":["Artificial Neural Networks (ANN)\n","\n","What is an Artificial Neural Network (ANN)?\n","\n","An Artificial Neural Network (ANN) is a type of machine learning model inspired by the structure and functioning of the human brain. It is a system of connected nodes, also known as neurons, organized in layers. ANNs are used to recognize patterns, make predictions, and solve problems that involve complex, non-linear relationships.\n","\n","An ANN consists of multiple layers:\n","\n","Input Layer: Receives the input data.\n","\n","Hidden Layers: Processes the input data through neurons and activations.\n","\n","Output Layer: Produces the final output.\n","\n","Each connection between neurons has a weight that determines the strength of the connection, and each neuron applies an activation function to its input to produce an output.\n","\n","How Does an ANN Work?\n","Input Layer:\n","The input layer receives the raw data, which can be a vector of features like pixel values in an image, sensor readings, etc.\n","\n","Hidden Layers:\n","The data from the input layer is passed to one or more hidden layers. Each neuron in a hidden layer processes the weighted sum of its inputs, adds a bias, and applies an activation function.\n","\n","Output Layer:\n","After passing through the hidden layers, the final output is produced in the output layer. For classification tasks, this could represent probabilities of the classes, while for regression tasks, it might represent a continuous value.\n","\n","Neural Network Architecture\n","Neurons (Nodes):\n","Each neuron takes in inputs, applies a weight to them, adds a bias, and then passes the result through an activation function to produce an output. This output is sent to the next layer of neurons.\n","\n","Layers:\n","\n","Input Layer: The first layer that receives the input data.\n","\n","Hidden Layers: Layers between the input and output layers that perform the bulk of computation.\n","\n","Output Layer: The last layer that produces the final result.\n","\n","Weights:\n","Weights are the parameters of the network that determine how much influence an input has on the output. These weights are adjusted during training to minimize the error.\n","\n","Bias:\n","Bias allows the network to have more flexibility and shift the activation function to fit the data better.\n","\n","Activation Functions\n","Activation functions determine the output of each neuron in a network. They introduce non-linearity to the network, allowing it to model complex relationships in data. Some common activation functions include:\n","\n","Sigmoid:\n","\n","𝜎\n","(\n","𝑥\n",")\n","=\n","1\n","1\n","+\n","𝑒\n","−\n","𝑥\n","σ(x)=\n","1+e\n","−x\n","\n","1\n","​\n","\n","The sigmoid function produces an output between 0 and 1, which is useful for binary classification.\n","\n","ReLU (Rectified Linear Unit):\n","\n","ReLU\n","(\n","𝑥\n",")\n","=\n","max\n","⁡\n","(\n","0\n",",\n","𝑥\n",")\n","ReLU(x)=max(0,x)\n","ReLU is commonly used in hidden layers. It outputs the input directly if it's positive, and zero otherwise.\n","\n","Tanh (Hyperbolic Tangent):\n","\n","tanh\n","(\n","𝑥\n",")\n","=\n","𝑒\n","𝑥\n","−\n","𝑒\n","−\n","𝑥\n","𝑒\n","𝑥\n","+\n","𝑒\n","−\n","𝑥\n","tanh(x)=\n","e\n","x\n"," +e\n","−x\n","\n","e\n","x\n"," −e\n","−x\n","\n","​\n","\n","Tanh outputs values between -1 and 1.\n","\n","Softmax:\n","Softmax is often used in the output layer for multi-class classification problems. It transforms the raw output into probabilities by ensuring that the sum of all output values equals 1.\n","\n","Training an ANN: Forward and Backpropagation\n","Forward Propagation:\n","During forward propagation, data is passed through the network layer by layer. The output of one layer is used as input to the next layer, and this continues until the output layer is reached.\n","\n","Loss Function (Cost Function):\n","After forward propagation, the predicted output is compared to the actual output, and the loss function (such as Mean Squared Error for regression or Cross-Entropy for classification) is computed to measure the error.\n","\n","Backpropagation:\n","To improve the model, the weights are adjusted based on the error from the loss function. Backpropagation involves computing the gradient of the loss function with respect to the weights and updating them to minimize the error. The optimization process is often done using Gradient Descent or more advanced variants like Adam.\n","\n","Gradient Descent:\n","Gradient descent is an optimization technique used to minimize the loss function. It updates the weights iteratively to reduce the error.\n","\n","Batch Gradient Descent: Uses the entire dataset to compute the gradient and update the weights.\n","\n","Stochastic Gradient Descent (SGD): Uses a single training sample to update weights, making it faster but more noisy.\n","\n","Mini-batch Gradient Descent: A compromise between the two above, using a subset of the training data.\n","\n","Types of Neural Networks\n","Feedforward Neural Network (FNN):\n","The simplest type of neural network where the data moves in one direction, from input to output, with no cycles.\n","\n","Convolutional Neural Networks (CNNs):\n","Specialized for processing grid-like data such as images. CNNs use convolutional layers to extract features, followed by pooling layers to reduce the spatial dimensions.\n","\n","Recurrent Neural Networks (RNNs):\n","RNNs are used for sequential data, where the output of previous steps is fed as input to the next steps. They are suitable for tasks like time series prediction or natural language processing.\n","\n","Generative Adversarial Networks (GANs):\n","GANs consist of two neural networks (generator and discriminator) that compete with each other. They are widely used for generating realistic data like images.\n","\n","Advantages of ANN\n","Powerful for Complex Patterns:\n","ANNs are capable of learning complex, non-linear relationships between inputs and outputs.\n","\n","Adaptable:\n","Neural networks can be trained to perform a wide range of tasks, from classification to regression and generation.\n","\n","Generalization:\n","With the right configuration and training, ANNs can generalize well to unseen data, making them effective for real-world tasks.\n","\n","Disadvantages of ANN\n","Require Large Datasets:\n","To train an effective ANN, large amounts of labeled data are often required.\n","\n","Computationally Expensive:\n","Training deep neural networks can be time-consuming and require significant computational resources, especially for large datasets.\n","\n","Interpretability:\n","ANNs are often considered \"black-box\" models, meaning they are difficult to interpret. This is a challenge when it comes to explaining the model’s decisions.\n","\n","Common Use Cases of ANN\n","Image Classification:\n","Classifying images into different categories, such as identifying objects in images.\n","\n","Speech Recognition:\n","Converting spoken words into text or identifying spoken commands.\n","\n","Natural Language Processing (NLP):\n","Tasks like sentiment analysis, language translation, and text generation.\n","\n","Financial Predictions:\n","Predicting stock prices, risk analysis, and fraud detection.\n","\n","Game AI:\n","Training agents to play games (e.g., AlphaGo, which uses deep learning).\n","\n","Example of an ANN:\n","Suppose you want to classify emails into two categories: spam or not spam. You have input features like the presence of specific words, the length of the email, etc.\n","You can use an ANN where:\n","\n","The input layer represents the features of the email,\n","\n","The hidden layers process this information to extract patterns, and\n","\n","The output layer provides the final classification, with probabilities for spam or not spam.\n","\n"],"metadata":{"id":"LhXyCfHGFugd"}},{"cell_type":"code","source":[],"metadata":{"id":"IZLVqg52FvJM"},"execution_count":null,"outputs":[]}]}