{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TITNkimH8gUC"
   },
   "source": [
    "**Dated 23/04/25: Aditi**\n",
    "**, M.Tech. CSA**\n",
    "**, 242211001**\n",
    "**, Timestamp: 10.30 AM.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWJrvpLednQi",
    "outputId": "33b58b3c-9386-42dc-cac2-576f20143e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ICCN LAB PC19\\.cache\\kagglehub\\datasets\\bhavikjikadara\\dog-and-cat-classification-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gD1D7XVdxoD",
    "outputId": "e08ca240-d373-4fa4-aaad-1717d4afc4c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2515\n",
      "           1       0.50      1.00      0.66      2485\n",
      "\n",
      "    accuracy                           0.50      5000\n",
      "   macro avg       0.25      0.50      0.33      5000\n",
      "weighted avg       0.25      0.50      0.33      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to extract grayscale image features and flatten them\n",
    "def load_image_data(image_dir, label, image_size=(64, 64)):\n",
    "    data, labels = [], []\n",
    "    for file in os.listdir(image_dir):\n",
    "        if file.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, file)\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "                img = img.resize(image_size)\n",
    "                data.append(np.array(img).flatten())      # Flatten the image\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                pass  # Skip corrupted or unreadable images\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Set dataset directories\n",
    "cat_path = \"/kaggle/input/dog-and-cat-classification-dataset/PetImages/Cat\"\n",
    "dog_path = \"/kaggle/input/dog-and-cat-classification-dataset/PetImages/Dog\"\n",
    "\n",
    "# Load and label the data\n",
    "cat_data, cat_labels = load_image_data(cat_path, label=0)\n",
    "dog_data, dog_labels = load_image_data(dog_path, label=1)\n",
    "\n",
    "# Combine cat and dog data\n",
    "X = np.vstack((cat_data, dog_data))\n",
    "y = np.concatenate((cat_labels, dog_labels))\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train a feed-forward neural network\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', max_iter=100, random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate model performance\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0CTpbktfjhE"
   },
   "source": [
    "**Question:** What were the limitations of FFNNs with high-dimensional image inputs?\n",
    "\n",
    "**Answer:**\n",
    "* FFNNs have multiple limitations when applied to high-dimensional image inputs. One of the primary issues is the large number of parameters involved. Since each pixel in an image becomes an input feature, even a relatively small grayscale image of size 64×64 results in 4,096 input nodes. When these are connected to hidden layers in a fully connected manner, the number of weights increases exponentially, making the model computationally expensive and highly prone to overfitting, especially when the available training data is limited. Additionally, FFNNs lack spatial awareness—they treat each pixel as an independent feature and do not account for local patterns or the spatial relationships between pixels. This means they are unable to capture important visual features like edges, textures, or shapes that are critical for understanding image content.\n",
    "* FFNNs do not have the property of translation invariance; they cannot recognize objects in varying positions across the image, which is essential in image classification tasks. They also do not utilize parameter sharing, which leads to redundant computations and inefficient use of model capacity.\n",
    "* FFNNs generally perform poorly on complex visual tasks compared to Convolutional Neural Networks (CNNs), which are specifically designed to handle image data by exploiting spatial hierarchies, local connectivity, and weight sharing. Therefore, while FFNNs may still be useful for simple or low-dimensional image tasks, CNNs are far more suitable and effective for real-world image processing applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "IppW40ibeoGX",
    "outputId": "a81c198a-0f18-4eb5-eda1-da6b3d1872f7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the dataset directory\n",
    "dataset_dir = \"/kaggle/input/dog-and-cat-classification-dataset/PetImages\"\n",
    "\n",
    "# Initialize the image data generator with rescaling and validation split\n",
    "image_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Create the training data generator\n",
    "train_data = image_generator.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Create the validation data generator\n",
    "validation_data = image_generator.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define a basic Feedforward Neural Network (BPNN) model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(64, 64, 3)),      # Flatten the input image\n",
    "    Dense(128, activation='relu'),         # First hidden layer\n",
    "    Dense(64, activation='relu'),          # Second hidden layer\n",
    "    Dense(1, activation='sigmoid')         # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train the model using the training and validation data\n",
    "model.fit(train_data, epochs=10, validation_data=validation_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
